{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "bk92nT2wT4U8"
   },
   "source": [
    "# Computer Vision Homework 02 - Panoramas, Image Features, and Calibration\n",
    "\n",
    "Contact: David C. Schedl (david.schedl@fh-hagenberg.at)\n",
    "\n",
    "Note: this is the starter pack for the **Visual Computing** homework. You do not need to use this template!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "GMb4sAogUarc"
   },
   "source": [
    "## Task:\n",
    "This exercise features a variety of tasks, ideas and algorithms we covered previously. The goal is to get familiar with the concepts and to apply them to a real-world problem.\n",
    "Therefore, for this exercise you get uncalibrated image pairs of thermal and RGB images of multiple scenes recorded with one of our BAMBI drones. \n",
    "\n",
    "Based on the images you should try to solve (some of) the following tasks and answer the following questions:\n",
    "* **Panorama stitching:** Create a panorama image from the RGB images. You can use the `ellipse` or `FH3` scenes for this task. Can you compute a panorama from the thermal images? \n",
    "* **Image features (thermal to RGB):** Detect and match image features from the thermal to the RGB images. How many features do you find? Which feature descriptors are suitable for this task? Which scenes work and which don't? How can you measure the quality of the matches?\n",
    "* **Camera Calibration:** Calibrate the camera with the thermal and/or RGB images. How many images do you need? Does it work at all? How well does the calibration work? How can you measure the quality of the calibration?\n",
    "* **Extrinsic Estimation:** Try to estimate the rotation and translation of the drone. How well does it work? How can you measure the quality of the estimation? \n",
    "\n",
    "Note that the cameras are mounted on a gimbal and therefore the cameras are perfectly aligned (no rotation and assume no translation between the thermal and RGB camera).\n",
    "The RGB camera has a larger field of view than the thermal camera. \n",
    "\n",
    "Use feature descriptors to find correspondences and match them. Matching can be done with the nearest neighbour distance or any other strategy. \n",
    "To estimate the extrinsic parameters, you can use OpenCV's [`findEssentialMat`](https://docs.opencv.org/4.x/d9/d0c/group__calib3d.html#gad245d60e64d0c1270dbfd0520847bb87), [`findFundamentalMat`](https://docs.opencv.org/4.x/d9/d0c/group__calib3d.html#gad245d60e64d0c1270dbfd0520847bb87), or any similar function. \n",
    "\n",
    "\n",
    "**Further comments/hints:**\n",
    "\n",
    "*   The thermal camera has severe distortions. Don't worry too much about imprecisions. \n",
    "*   If you have troubles with the intrinsic calibration I provide a ground truth calibration for both cameras below. However, try to it without the ground truth first.\n",
    "*   Think about the problem ðŸ¤”, solve it, and critically evaluate your solution.\n",
    "*   You can downscale the RGB images to speed up the computation.\n",
    "*   Summarize your ideas and findings in the report. \n",
    "\n",
    "\n",
    "\n",
    "**Have fun!** ðŸ˜¸\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "j14w-SeSOC9k"
   },
   "source": [
    "## Initialization and Download\n",
    "\n",
    "Let's import useful libraries, first. \n",
    "Then download some scenes with `curl`.\n",
    "\n",
    "**Scenes:**\n",
    "\n",
    "You can use the following scenes `ellipse`, `FH3`, `forest`, `hut`. \n",
    "They are located in the `data` folder after download and are well suited for various tasks:\n",
    "* `ellipse` scene showing the FH's ellipse. Drone was hovering and only rotating around the up-axis. Perfect for panorama stitching.\n",
    "* `FH3`  scene showing the FH's FH3 building. Drone was flying at a horizontal distance of around 60m to the building. Suitable for panorama stitching.\n",
    "* `forest` scene showing a forest. Drone was flying 50m above the ground. There is no overlap between the images, so panorama stitching is not possible.\n",
    "* `hut` scene showing a hut in a zoo. Drone was flying in circular movements around the front of the hut. Might be suitable for panorama stitching (but will be hard).\n",
    "\n",
    "\n",
    "Furthermore, let's define utility functions to display images, in Jupyter Notebooks. OpenCV's `imshow` does not work and matplotlib's `imshow` needs special treatment due to color channel handling (RGB vs. BGR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SETUP\n",
    "if \"google.colab\" in str(get_ipython()):\n",
    "    # install a newer opencv version on Colab. The older OpenCV versions do not support SIFT!\n",
    "    !pip install opencv-contrib-python>=4.5.*\n",
    "\n",
    "# import the libraries we use\n",
    "import os\n",
    "import cv2  # openCV\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob  # library for loading images from a directory\n",
    "\n",
    "\n",
    "def download_cv_dataset(dataset: str, extract_to: str = \"./data\"):\n",
    "    # change the current working directory\n",
    "    old_working_dir = os.getcwd()\n",
    "    if not os.path.exists(extract_to):\n",
    "        os.mkdir(extract_to)\n",
    "    os.chdir(extract_to)\n",
    "    try:\n",
    "        # check if the file exists\n",
    "        if not os.path.exists(os.path.join(extract_to, dataset)):\n",
    "            !curl -LJO \"https://raw.githubusercontent.com/Digital-Media/cv_data/main/{dataset}\" --silent\n",
    "        import zipfile\n",
    "\n",
    "        with zipfile.ZipFile(dataset, \"r\") as zip_ref:\n",
    "            zip_ref.extractall(\".\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: Please check if the dataset {dataset} exists.\")\n",
    "        # print the error message\n",
    "        print(e)\n",
    "    finally:\n",
    "        # change back to the original working directory\n",
    "        os.chdir(old_working_dir)\n",
    "\n",
    "\n",
    "# utility function(s)\n",
    "def imshow(image, *args, **kwargs):\n",
    "    \"\"\"A replacement for cv2.imshow() for use in Jupyter notebooks using matplotlib.\n",
    "\n",
    "    Args:\n",
    "      image : np.ndarray. shape (N, M) or (N, M, 1) is an NxM grayscale image. shape\n",
    "        (N, M, 3) is an NxM BGR color image.\n",
    "    \"\"\"\n",
    "    if len(image.shape) == 3:\n",
    "        # Height, width, channels\n",
    "        # Assume BGR, do a conversion\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Draw the image\n",
    "    plt.imshow(image, *args, **kwargs)\n",
    "    # We'll also disable drawing the axes and tick marks in the plot, since it's actually an image\n",
    "    plt.axis(\"off\")\n",
    "    # Make sure it outputs\n",
    "    # plt.show()\n",
    "\n",
    "\n",
    "# read the images from the dataset folder\n",
    "def read_images(dataset: str):\n",
    "    # get the list of images from the dataset folder\n",
    "    T_img_files = sorted(glob.glob(f\"./data/{dataset}/T_*.png\"))\n",
    "    W_img_files = sorted(glob.glob(f\"./data/{dataset}/W_*.png\"))\n",
    "    # assert that the number of images is the same\n",
    "    assert len(T_img_files) == len(W_img_files)\n",
    "\n",
    "    # if there are no images, raise an error\n",
    "    if len(T_img_files) == 0:\n",
    "        raise ValueError(f\"No images found in the {dataset} folder.\")\n",
    "\n",
    "    T_imgs = []\n",
    "    W_imgs = []\n",
    "\n",
    "    for i in range(len(T_img_files)):\n",
    "        # read the images\n",
    "        T_img = cv2.imread(T_img_files[i])\n",
    "        W_img = cv2.imread(W_img_files[i])\n",
    "        # add the images to a list\n",
    "        W_imgs.append(W_img)\n",
    "        T_imgs.append(T_img)\n",
    "\n",
    "    return {\"Thermal\": T_imgs, \"RGB\": W_imgs}\n",
    "\n",
    "\n",
    "download_cv_dataset(\n",
    "    \"thermal-rgb_ellipse.zip\"\n",
    ")  # <-- scene showing the FH's ellipse. Drone was hovering and only rotating around the up-axis. Perfect for panorama stitching.\n",
    "download_cv_dataset(\n",
    "    \"thermal-rgb_FH3.zip\"\n",
    ")  # <-- scene showing the FH's FH3 building. Drone was flying at a horizontal distance of around 60m to the building. Suitable for panorama stitching.\n",
    "download_cv_dataset(\n",
    "    \"thermal-rgb_forest.zip\"\n",
    ")  # <-- scene showing a forest. Drone was flying 50m above the ground. There is no overlap between the images, so panorama stitching is not possible.\n",
    "download_cv_dataset(\n",
    "    \"thermal-rgb_hut.zip\"\n",
    ")  # <-- scene showing a hut in a zoo. Drone was flying in circular movements around the front of the hut. Might be suitable for panorama stitching (but will be hard).\n",
    "\n",
    "\n",
    "# read the images\n",
    "# use one of the following datasets: \"ellipse\", \"FH3\", \"forest\", \"hut\"\n",
    "images = read_images(\"ellipse\")\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.subplot(121), plt.title(\"Thermal\")\n",
    "imshow(images[\"Thermal\"][0])\n",
    "plt.subplot(122), plt.title(\"RGB\")\n",
    "imshow(images[\"RGB\"][0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ground Truth Intrinsic Calibration\n",
    "Below you can find the ground truth intrinsic calibration for both cameras. Use it if you have troubles with the intrinsic calibration.\n",
    "Especially the distortion coefficients might be handy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_calibrations = {\n",
    "    \"Thermal\": {\n",
    "        \"K\": [\n",
    "            [1523.7602359891657, 0.0, 618.0480346862191],\n",
    "            [0.0, 1491.3570424347292, 507.1000881569456],\n",
    "            [0.0, 0.0, 1.0],\n",
    "        ],\n",
    "        \"dist\": [\n",
    "            [\n",
    "                -0.3880250851012345,\n",
    "                0.3744059275961452,\n",
    "                0.0010497689153120373,\n",
    "                0.00011610446402566044,\n",
    "                0.0,\n",
    "            ]\n",
    "        ],\n",
    "    },\n",
    "    \"RGB\": {\n",
    "        \"K\": [\n",
    "            [2888.178324915765, 0.0, 1929.0179499431672],\n",
    "            [0.0, 2819.3160759551897, 1070.7804294784548],\n",
    "            [0.0, 0.0, 1.0],\n",
    "        ],\n",
    "        \"dist\": [\n",
    "            [\n",
    "                0.13853585738444427,\n",
    "                -0.25508562557544706,\n",
    "                0.00020336601637138113,\n",
    "                -0.0009057472383396885,\n",
    "                0.0,\n",
    "            ]\n",
    "        ],\n",
    "    },\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overlaying RGB and Thermal Images\n",
    "\n",
    "Once you have the intrinsic calibrations, you can overlay the RGB and thermal images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hard coded camera matrix for undistortion\n",
    "dst_size = (2024, 1024)\n",
    "f = min(*dst_size)\n",
    "new_camera_matrix = np.array(\n",
    "    [[f, 0.0, dst_size[0] / 2 - 0.5], [0.0, f, dst_size[1] / 2 - 0.5], [0.0, 0.0, 1.0]]\n",
    ")\n",
    "\n",
    "\n",
    "def overlay_images(\n",
    "    images, calibrations, selected_img_id=0, show_individual_images=False\n",
    "):\n",
    "    plt.figure(figsize=(20, 8))\n",
    "    for i, camera in enumerate(images.keys()):\n",
    "        # calib = saver.get(get_resource(\"calibration.db\"), drone_name, camera, normalize_calibration=True)\n",
    "        calib = calibrations.get(camera)\n",
    "        assert calib is not None\n",
    "\n",
    "        camera_matrix = np.array(calib[\"K\"])\n",
    "        # k1, k2, p1, p2, k3\n",
    "        dist_coefs = np.array(calib[\"dist\"])\n",
    "\n",
    "        if selected_img_id >= len(images[camera]):\n",
    "            print(\"WARNING: selected_img_id is out of range.\")\n",
    "            selected_img_id = len(images[camera]) - 1\n",
    "\n",
    "        img = images[camera][selected_img_id]\n",
    "\n",
    "        # remove the the lens distortions\n",
    "        mapx, mapy = cv2.initUndistortRectifyMap(\n",
    "            camera_matrix, dist_coefs, None, new_camera_matrix, dst_size, cv2.CV_32FC1\n",
    "        )\n",
    "        dst = cv2.remap(img, mapx, mapy, cv2.INTER_CUBIC)\n",
    "        # print(dst_T.shape)\n",
    "\n",
    "        if show_individual_images:\n",
    "            plt.subplot(1, len(calibrations), i + 1)\n",
    "            imshow(dst, cmap=\"gray\")\n",
    "            plt.title(f\"undistorted {camera} image\")\n",
    "\n",
    "        if camera == \"RGB\":\n",
    "            # apply an edge detector on the wide image\n",
    "            dst = cv2.Canny(dst.copy(), 100, 200)\n",
    "            rgb_img_edge = cv2.cvtColor(dst, cv2.COLOR_GRAY2RGB)\n",
    "        else:\n",
    "            thermal_img = dst.copy()\n",
    "            cmp_img = thermal_img.copy()\n",
    "    plt.show()  # show the images\n",
    "\n",
    "    cmp_img[:, :, 1] = rgb_img_edge[:, :, 1]  # copy a channel from the thermal image\n",
    "\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    imshow(cmp_img, cmap=\"gray\")\n",
    "    plt.title(f\"RGB image with a channel from thermal image\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "overlay_images(images, gt_calibrations, 6)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "HW03_Calibration.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "0bae4c9257a18836fb2e3dc2d0aeb6355625d596c4075009294ab101cd3e0d3c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
