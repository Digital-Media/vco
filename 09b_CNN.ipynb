{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "wg0d5jojmFFy"
   },
   "source": [
    "# Tutorial 09b - CNN with PyTorch\n",
    "\n",
    "## Dr. David C. Schedl\n",
    "\n",
    "Note: this tutorial is geared towards students **experienced in programming** and aims to introduce you to **PyTorch and CNNs**.\n",
    "\n",
    "\n",
    "\n",
    "## Setup\n",
    "As first step, we need to import the necessary libraries. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR10 with PyTorch\n",
    "\n",
    "Let's try to classify the CIFAR10 dataset. We can use the torchvision package to load the CIFAR10 dataset. \n",
    "After loading the dataset, we'll need to preprocess the images by reshaping them to a 1D tensor and normalizing the pixel values. The `transform` takes care of this.\n",
    "\n",
    "Afterwards let's display some images from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "!pip install torchinfo # external package to print model summary (like TensorFlow's model.summary())\n",
    "\n",
    "batch_size = 100\n",
    "\n",
    "# Load and preprocess the CIFAR10 dataset\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# the labels will be put in a separate vector as the original is just numbers, but we want text labels \n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "# display some images\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# functions to show an image\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# show 10 images\n",
    "plt.title('|'.join('% 5s' % classes[labels[j].item()] for j in range(10)))\n",
    "imshow(torchvision.utils.make_grid(images[:10], nrow=10))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LeNet-5 in PyTorch\n",
    "\n",
    "Below you can find the code for a (modernized) LeNet-5 architecture in PyTorch. \n",
    "Inspired by [this](https://towardsdatascience.com/implementing-yann-lecuns-lenet-5-in-pytorch-5e05a0911320) blog post."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a model\n",
    "inputs, classes = next(iter(trainloader))\n",
    "input_shape = inputs[0].shape\n",
    "print(\"input:\", input_shape)\n",
    "nb_classes = 10\n",
    "\n",
    "class CNNModel(nn.Module):\n",
    "\n",
    "    def __init__(self, input_shape, nb_classes, legacy=True):\n",
    "        super(CNNModel, self).__init__()\n",
    "\n",
    "        self.act = nn.Sigmoid() if legacy else nn.ReLU()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(input_shape[0], 6 if legacy else 20, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2),)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
    "        self.conv2 = nn.Conv2d(6 if legacy else 20, 16 if legacy else 50 , kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(input_shape[1]//4*input_shape[2]//4*(16 if legacy else 50), 500)\n",
    "        self.fc2 = nn.Linear(500, nb_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.act(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "model = CNNModel(input_shape, nb_classes, legacy=True) # instance the model\n",
    "print( \"output:\", model(inputs).shape ) # check the output shape of the model -> (batch_size, nb_classes)\n",
    "\n",
    "# summary of the model\n",
    "from torchinfo import summary\n",
    "summary(model, inputs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU\n",
    "\n",
    "Running the code on the GPU is easy. Just move the model and the data to the GPU with `model.to(device)` and `data.to(device)`.\n",
    "You can check if you have a GPU available with `torch.cuda.is_available()`.\n",
    "\n",
    "When data is moved to the GPU it is stored on the GPU's memory. You cannot access it from the CPU anymore. Thus, you need to move it back to the CPU with `data.cpu()`.\n",
    "\n",
    "If you want to use a GPU in Colab, go to the menu and select **Edit** -> **Notebook settings** -> **Hardware accelerator** -> switch to **GPU**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you want to use a GPU (recommended) use `tensor.to(device)`\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "if device.type != \"cuda\":\n",
    "    print(\"Using CPU! things will be slow! :(\")\n",
    "\n",
    "model = model.to(device) # move the model to the GPU\n",
    "output = model(inputs.to(device)) # move the input to the GPU and run the model\n",
    "output = output.cpu() # move the output back to the CPU for further processing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "For training we define the loss function and optimizer. Let's use the cross-entropy loss function and a stochastic gradient descent (SGD) or Adam optimizer to train the model.\n",
    "\n",
    "Then we need to loop over the training dataset, feed the images and labels to the model, compute the loss, perform backpropagation to update the model's parameters, and repeat for a certain number of epochs.\n",
    "\n",
    "Afterwards we can test the model on the test dataset. We can use the `torch.no_grad()` context manager to temporarily set all the requires_grad flag to false. This will reduce memory usage and speed up computations. We don't need to compute gradients in the testing phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = CNNModel()\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(10):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        if torch.cuda.is_available():\n",
    "            # move the data to the GPU\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # keep loss for statistics\n",
    "        running_loss += loss.item()\n",
    "    # print statistics\n",
    "    print('Epoch %d loss: %.3f' % (epoch + 1, running_loss / len(trainloader)))\n",
    "\n",
    "print('Finished Training')\n",
    "\n",
    "# Test the model\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        if torch.cuda.is_available():\n",
    "            # move the data to the GPU\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at a few images from the test set and print the model's predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get some random test images\n",
    "images, labels = next(iter(testloader))\n",
    "\n",
    "_model = model.cpu() # move the model to the CPU\n",
    "\n",
    "\n",
    "# set up a figure\n",
    "fig = plt.figure(figsize=(15, 7))\n",
    "fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05)\n",
    "\n",
    "_, prediction_label = torch.max(_model(images).data, 1)\n",
    "\n",
    "total, correct = 0, 0\n",
    "# plot the images: each image is 28x28 pixels\n",
    "for i,img in enumerate(images[:50]):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    ax = fig.add_subplot(5, 10, i + 1, xticks=[], yticks=[])\n",
    "    ax.imshow(np.transpose(npimg, (1, 2, 0)), interpolation='nearest')\n",
    "\n",
    "\n",
    "    img_text = f'{classes[prediction_label[i]]} [{classes[labels[i]]}]'\n",
    "\n",
    "    if prediction_label[i] == labels[i]:\n",
    "        # label the image with the blue text\n",
    "        ax.text(0.1, 0.1, img_text, color='lightgreen', transform=ax.transAxes)\n",
    "        ax.tick_params(color='green', labelcolor='green')\n",
    "        for spine in ax.spines.values():\n",
    "            spine.set_edgecolor('green')\n",
    "        correct += 1\n",
    "    else:\n",
    "        # label the image with the red text\n",
    "        ax.text(0.1, 0.1, img_text, color='darkred', transform=ax.transAxes)\n",
    "        ax.tick_params(color='red', labelcolor='red')\n",
    "        for spine in ax.spines.values():\n",
    "            spine.set_edgecolor('red')\n",
    "    total += 1\n",
    "\n",
    "print(f'Accuracy: {correct/total*100:.2f}% for {total} test images')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "0a05e4fa746b81761c76a645b508c0f51cdd970f4b4b50ae36c6a73f9a174174"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
